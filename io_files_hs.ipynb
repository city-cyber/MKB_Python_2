{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edQI-m-cCgpV"
      },
      "source": [
        "# Практика по теме «Работа с файлами и пакетами»\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Этот блок создает все необходимые файлы и папки\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Создание основного файла с логами ---\n",
        "log_content = [\n",
        "    \"timestamp,user_id,source_ip\",\n",
        "    \"2025-09-21T10:00:01,user_003,81.161.42.201\",\n",
        "    \"2025-09-21T10:01:15,user_001,195.8.80.5\",\n",
        "    \"2025-09-21T10:02:30,user_004,8.8.8.8\", # Подозрительный IP\n",
        "    \"2025-09-21T10:02:45,user_002,171.25.193.99\",\n",
        "    \"2025-09-21T10:03:00,user_005,213.180.204.62\", # Пользователя нет в базе\n",
        "    \"2025-09-21T10:04:10,user_001,195.8.80.5\",\n",
        "    \"2025-09-21T10:05:00,user_003,193.232.147.4\", # Подозрительный IP\n",
        "]\n",
        "with open('log.csv', 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(log_content))\n",
        "\n",
        "# --- Создание JSON-файла с данными пользователей ---\n",
        "# Формат: JSON Lines (один JSON-объект на строку)\n",
        "user_data_content = [\n",
        "    {\"user_id\": \"user_001\", \"name\": \"Ivan Ivanov\", \"department\": \"Sales\"},\n",
        "    {\"user_id\": \"user_002\", \"name\": \"Anna Petrova\", \"department\": \"Development\"},\n",
        "    {\"user_id\": \"user_003\", \"name\": \"Sergey Smirnov\", \"department\": \"Marketing\"},\n",
        "    {\"user_id\": \"user_004\", \"name\": \"Olga Sidorova\", \"department\": \"Development\"},\n",
        "]\n",
        "with open('user_data.json', 'w', encoding='utf-8') as f:\n",
        "    for line in user_data_content:\n",
        "        f.write(json.dumps(line) + '\\n')\n",
        "\n",
        "# --- Создание логов с конечных точек в сложной структуре папок ---\n",
        "Path(\"endpoint_logs/windows/servers\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"endpoint_logs/linux/workstations\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open('endpoint_logs/windows/servers/dc01.log', 'w', encoding='utf-8') as f:\n",
        "    f.write(\"INFO: User 'user_004' logged on successfully.\\n\")\n",
        "    f.write(\"WARN: High CPU usage detected.\\n\")\n",
        "\n",
        "with open('endpoint_logs/linux/workstations/dev05.log', 'w', encoding='utf-8') as f:\n",
        "    f.write(\"Sep 21 10:02:30 dev05 sshd[12345]: Accepted publickey for user_004 from 8.8.8.8 port 12345 ssh2\\n\")\n",
        "\n",
        "# --- Создание \"сломанного\" лога в другой кодировке ---\n",
        "broken_log_content = \"user_id,action\\nuser_001,Вошел в систему\\nuser_002,Обновил профиль\"\n",
        "with open('legacy_log.csv', 'w', encoding='cp1251') as f:\n",
        "    f.write(broken_log_content)\n",
        "\n",
        "# --- Создание \"сломанного\" JSON-файла для демонстрации обработки ошибок ---\n",
        "# В третьей строке намеренно пропущена запятая между полями \"name\" и \"department\"\n",
        "user_data_broken_content = [\n",
        "    '{\"user_id\": \"user_001\", \"name\": \"Ivan Ivanov\", \"department\": \"Sales\"}',\n",
        "    '{\"user_id\": \"user_002\", \"name\": \"Anna Petrova\", \"department\": \"Development\"}',\n",
        "    '{\"user_id\": \"user_003\", \"name\": \"Sergey Smirnov\" \"department\": \"Marketing\"}',\n",
        "    '{\"user_id\": \"user_004\", \"name\": \"Olga Sidorova\", \"department\": \"Development\"}'\n",
        "]\n",
        "with open('user_data_broken.json', 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(user_data_broken_content))\n",
        "\n",
        "\n",
        "# --- Создание CSV-файла с запятыми внутри полей ---\n",
        "# Поле user_agent содержит запятые, что сломает простой .split(',')\n",
        "vpn_log_complex_content = [\n",
        "    'timestamp,user_id,source_ip,user_agent',\n",
        "    '2025-09-18T11:00:01,user_001,81.161.42.201,\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"',\n",
        "    '2025-09-18T11:01:15,user_002,195.8.80.5,\"SomeApp, Version 2.1, Build 1234\"'\n",
        "]\n",
        "with open('log_complex.csv', 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(vpn_log_complex_content))\n",
        "\n",
        "\n",
        "# --- Создание файла конфигурации для импорта ---\n",
        "config_content = [\n",
        "    'SUSPICIOUS_IPS = {',\n",
        "    '    \"8.8.8.8\", # Google DNS, аномально для подключения',\n",
        "    '    \"193.232.147.4\"  # IP из известного списка угроз',\n",
        "    '}'\n",
        "]\n",
        "\n",
        "with open('config.py', 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(config_content))\n"
      ],
      "metadata": {
        "id": "xkXI2-_paR5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "pbcH57-MksRr"
      },
      "source": [
        "# Проверка связи"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если у вас нет звука:\n",
        "*   убедитесь, что на вашем устройстве и в колонках включён звук\n",
        "*   обновите страницу вебинара или закройте страницу и заново присоединитесь к вебинару\n",
        "*   откройте вебинар в другом браузере\n",
        "*   перезагрузите ваше устройство и попытайтесь войти снова"
      ],
      "metadata": {
        "id": "b7S23zMKsneW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поставьте в чат:\n",
        "* «+» — если видно и слышно\n",
        "* «–» — если нет"
      ],
      "metadata": {
        "id": "bXA6tiROs7M5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGmyF92MksRs"
      },
      "source": [
        "## О спикере"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Олег Булыгин**\n",
        "- эксперт по Python и data science;\n",
        "- занимался аналитикой СМИ, IT-аудитом в финтехе;\n",
        "- работал в научно-производственных компаниях космической отрасли;\n",
        "- с 2020 года реализую собственные проекты, занимаюсь IT-образованием и консультированием;\n",
        "- с 2017 года в IT-образовании, стремлюсь сделать обучение качественным и честным для всех, кто хочет развиваться в IT-сфере."
      ],
      "metadata": {
        "id": "Ofl6rR2wuA3X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeTexD3tksRt"
      },
      "source": [
        "## Правила участия"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Приготовьте блокнот и ручку, чтобы записывать важные мысли и идеи\n",
        "*   Продолжительность вебинара — 80 минут\n",
        "*   Вы можете писать свои вопросы в чате или задавать их вслух\n",
        "*   Запись вебинара будет доступна в личном кабинете"
      ],
      "metadata": {
        "id": "pxxd0nQSuVwq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwWum4yz_t4E"
      },
      "source": [
        "# Цели занятия\n",
        "\n",
        "- На практике научиться работать с файлами и пакетами в Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNrQJFkxt5XO"
      },
      "source": [
        "# План занятия"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Введение и постановка задачи\n",
        "2. Чтение файлов\n",
        "3. Работа со структурированными данными\n",
        "4. Проблемы на практике\n",
        "5. Работа с окружением\n",
        "6. Формирование отчёта"
      ],
      "metadata": {
        "id": "8RGzsWrdyUJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Введение и постановка задачи\n",
        "\n",
        "С какими текстовыми файлами чаще всего сталкивается аналитик ИБ:\n",
        "- логи,\n",
        "- отчёты,\n",
        "- дампы.\n",
        "\n",
        "**Как Python на практике помогает автоматизировать работу с текстовыми данными:**\n",
        "*   **парсинг логов** — Python-скрипт может за минуты найти нужную информацию в гигабайтах сырых данных от SIEM-систем (Splunk, ELK);\n",
        "*   **анализ IoC (Indicators of Compromise)** — Python-скрипт автоматически проверит список из тысяч подозрительных IP-адресов по API VirusTotal и отсортирует их по уровню угрозы;\n",
        "*   **обогащение данных** — с помощью Python можно автоматически добавлять новые данные в исходный лог.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Смоделируем ситуацию\n",
        "\n",
        "Вы получили уведомление о возможной аномальной активности в сетевых подключениях. Ваша задача — провести первичное расследование.\n",
        "\n",
        "\n",
        "У вас есть данные:\n",
        "1.  `log.csv` — основной лог подключений. Содержит временную метку, ID пользователя и его IP-адрес. Файл потенциально очень большой.\n",
        "2.  `user_data.json` — файл с метаданными пользователей (имя, департамент). Файл небольшой.\n",
        "3.  Папка `endpoint_logs/` — директория с логами с рабочих станций и серверов.\n",
        "\n",
        "Ваша цель — написать скрипт, который:\n",
        "- обогатит данные из VPN-лога информацией о пользователях,\n",
        "- выявит подозрительные сессии,\n",
        "- сформирует первичный отчет `incident_report.txt`.\n"
      ],
      "metadata": {
        "id": "FdPTmC80akPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Чтение файлов\n",
        "\n",
        "Прежде чем открыть файл, нужно правильно до него дойти. Работа с путями к файлам — это фундамент автоматизации, ошибка в пути может остановить всю автоматизацию, особенно при переносе скрипта с Windows-машины на Linux-сервер.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lLxO6loF817n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Современный подход к путям: `pathlib` против `os.path`\n",
        "\n",
        "**Проблемы `os.path`:**\n",
        "*   конкатенация строк: `path = 'folder' + '/' + 'file.txt'` — это ненадежно, так как в ОС Windows используется `\\`, а в Linux `/`, такой код ломается при переносе;\n",
        "*   громоздкость: такие функции, как `os.path.join()`, `os.path.basename()`, `os.path.exists()`, рассредоточены по модулю и делают код менее читаемым.\n",
        "\n",
        "**`pathlib`** решает эти проблемы, представляя путь как объект со своими методами и свойствами."
      ],
      "metadata": {
        "id": "GN0DWMUgHiCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os"
      ],
      "metadata": {
        "id": "zueD7GT6CM4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задача: получить путь к файлу dc01.log в папке endpoint_logs/windows/servers"
      ],
      "metadata": {
        "id": "J1z3EmQx84PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Устаревший способ — os.path.join().\n",
        "# Требует явного вызова функции, выглядит громоздко.\n",
        "old_way = os.path.join('endpoint_logs', 'windows', 'servers', 'dc01.log')\n",
        "print(f\"Старый способ (os.path):      {old_way}\")"
      ],
      "metadata": {
        "id": "Qk6Z8s6585fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Современный способ — pathlib.\n",
        "# Использует интуитивно понятный оператор '/', как в файловой системе.\n",
        "modern_way = Path('endpoint_logs') / 'windows' / 'servers' / 'dc01.log'\n",
        "print(f\"Современный способ (pathlib): {modern_way}\")"
      ],
      "metadata": {
        "id": "E2tySN1K0yTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кроме того объект `Path` дает нам массу полезной информации из коробки:"
      ],
      "metadata": {
        "id": "-VDZkuK3867W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_path = Path('endpoint_logs/windows/servers/dc01.log')\n",
        "\n",
        "print(f\"\\nПолный путь: {log_path}\")\n",
        "print(f\"Родительская папка: {log_path.parent}\")\n",
        "print(f\"Имя файла: {log_path.name}\")\n",
        "print(f\"Имя файла без расширения: {log_path.stem}\")\n",
        "print(f\"Расширение: {log_path.suffix}\")\n",
        "\n",
        "# Проверки — это методы объекта, а не отдельные функции\n",
        "print(f\"\\nЭто файл? {log_path.is_file()}\")\n",
        "print(f\"Это папка? {log_path.is_dir()}\")\n",
        "print(f\"Существует ли такой путь? {log_path.exists()}\")\n",
        "\n",
        "non_existent_path = Path('non_existent_file.txt')\n",
        "print(f\"Существует ли '{non_existent_path}'? {non_existent_path.exists()}\")"
      ],
      "metadata": {
        "id": "0DG72uZj88Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| Задача | `os.path` (старый подход) | `pathlib` (современный стандарт) |\n",
        "| :--- | :--- | :--- |\n",
        "| **Собрать путь** | `os.path.join('dir', 'subdir', 'file')` | `Path('dir') / 'subdir' / 'file'` |\n",
        "| **Получить родителя**| `os.path.dirname(path)` | `p.parent` |\n",
        "| **Получить имя файла**| `os.path.basename(path)` | `p.name` |\n",
        "| **Проверить наличие** | `os.path.exists(path)` | `p.exists()` |\n",
        "| **Прочитать файл** | `f = open(path); f.read()` | `p.read_text()` |\n",
        "\n",
        "<br>\n",
        "\n",
        "###**Вывод**\n",
        "Рекомендуем использовать `pathlib`, он делает код чище, надежнее и проще для чтения другими специалистами."
      ],
      "metadata": {
        "id": "x9rQWWFr89pO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Открытие файлов: `with open(...) as f:`\n",
        "\n",
        "Золотое правило работы с файлами в Python — использовать менеджер контекста **`with`**.\n",
        "\n",
        "\n",
        "Эта конструкция гарантирует, что файл будет автоматически и корректно закрыт, даже если внутри блока `with` произойдет ошибка.\n",
        "\n",
        "Если файл открыт командой `f = open(...)`, его необходимо явно закрыть командой (`f.close()`). Иначе могут произойти утечки ресурсов или повреждение данных.\n",
        "\n",
        "<br>\n",
        "\n",
        "Откроем лог безопсно и посмотрим на первую строку."
      ],
      "metadata": {
        "id": "1R8TF10z9Tt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_path = Path('log.csv')\n",
        "\n",
        "# Безопасный способ открытия\n",
        "with open(log_path, mode='r', encoding='utf-8') as f:\n",
        "    first_line = f.readline()\n",
        "    print(f\"Первая строка файла: {first_line.strip()}\")\n",
        "\n",
        "# После выхода из блока `with` файл `f` автоматически закрыт."
      ],
      "metadata": {
        "id": "Ava0yv4I9UDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Зесь:\n",
        "*   `mode='r'` — режим чтения (`read`), это режим по умолчанию;\n",
        "*   `encoding='utf-8'` — явное указание кодировки, указывать кодировку — хорошая практика.\n",
        "\n"
      ],
      "metadata": {
        "id": "4qjZjzVm9XfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Режимы доступа к файлам\n",
        "\n",
        "*   **`'r'`** (read) — чтение исходных данных без их изменения;\n",
        "*   **`'w'`** (write) — перезапись файла (если открываемый файл ранее не существовал, он будет создан, если файл существовал — его изначальное содержимое сотрется);\n",
        "*   **`'a'`** (append) — добавление данных в существующий файл (данные добавляются в конец файла, изначальное содержимое не удаляется).\n",
        "\n",
        "<br>\n",
        "\n",
        "**Ошибка новичка** — использовать режим `'w'` в цикле.\n",
        "\n",
        "**Пример:** необходимо записать в отчёт IP-адреса из лога."
      ],
      "metadata": {
        "id": "-M3V4q-f2s9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report_path = Path('incident_report.txt')\n",
        "vpn_log_path = Path('log.csv')\n",
        "\n",
        "# Некорректный подход\n",
        "with open(log_path, 'r', encoding='utf-8') as f_in:\n",
        "    # Пропускаем заголовок\n",
        "    next(f_in)\n",
        "\n",
        "    for line in f_in:\n",
        "        # Открываем файл для записи на каждой итерации цикла\n",
        "        with open(report_path, 'w', encoding='utf-8') as f_out:\n",
        "            ip_address = line.strip().split(',')[2]\n",
        "            f_out.write(f\"Обнаружен IP-адрес: {ip_address}\\n\")\n",
        "\n",
        "print(\"--- Содержимое отчёта после некорректного подхода ---\")\n",
        "with open(report_path, 'r', encoding='utf-8') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "i04X-ua89XtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Итог:** в файле осталась только последняя запись. Каждый раз, когда файл открывали в режиме `'w'`, он стирал предыдущее содержимое.\n",
        "\n",
        "**Корректный подход:** использовать режим `'w'` для заголовка и режим `'a'` — для данных.\n",
        "\n",
        "**Скорректируем предыдущий код:** создадим файл один  раз и запишем заголовок, если нужно, в режиме `'w'`, а затем в цикле добавим строки в режиме `'a'`."
      ],
      "metadata": {
        "id": "lAgAk7qH9aJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report_path = Path('incident_report.txt')\n",
        "vpn_log_path = Path('log.csv')\n",
        "\n",
        "# 1. Создаем/очищаем файл и пишем заголовок\n",
        "with open(report_path, 'w', encoding='utf-8') as f_out:\n",
        "    f_out.write(\"--- Отчет по сессиям ---\\n\")\n",
        "\n",
        "# 2. Открываем лог для чтения\n",
        "with open(vpn_log_path, 'r', encoding='utf-8') as f_in:\n",
        "    next(f_in) # Пропускаем заголовок\n",
        "\n",
        "    # 3. В цикле добавляем данные в отчет в режиме 'a'\n",
        "    for line in f_in:\n",
        "        ip_address = line.strip().split(',')[2]\n",
        "\n",
        "        with open(report_path, 'a', encoding='utf-8') as f_out:\n",
        "            f_out.write(f\"Обнаружен IP-адрес: {ip_address}\\n\")\n",
        "\n",
        "with open(report_path, 'r', encoding='utf-8') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "rA99erun9bdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь все записи на месте. Этот паттерн — один из самых распространенных при обработке данных и формировании отчётов.\n",
        "\n"
      ],
      "metadata": {
        "id": "IR9I2wuo9dYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Построчное чтение лога\n",
        "\n",
        "Проведем первичный анализ `log.csv`. Для  этого необходимо прочитать файл построчно, так как он может быть очень большим и не поместиться в память, и разобрать каждую строку на компоненты.\n",
        "\n",
        "1.   Метод `.strip()` убирает невидимые символы по краям строки, например пробелы и символ переноса строки `\\n`.\n",
        "2.   Метод `.split(',')` разделяет строку на список по указанному разделителю (в нашем случае — по запятой)."
      ],
      "metadata": {
        "id": "lP6JJgOA242S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vpn_log_path = Path('log.csv')\n",
        "\n",
        "with open(vpn_log_path, 'r', encoding='utf-8') as f:\n",
        "    # Читаем и выводим заголовок отдельно\n",
        "    header = f.readline().strip().split(',')\n",
        "    print(f\"Заголовки файла: {header}\")\n",
        "\n",
        "    # Обрабатываем остальные строки в цикле\n",
        "    for line in f:\n",
        "        # 1. Очищаем строку от лишних символов\n",
        "        cleaned_line = line.strip()\n",
        "\n",
        "        # 2. Разделяем строку на части\n",
        "        parts = cleaned_line.split(',')\n",
        "\n",
        "        # 3. Выводим результат\n",
        "        print(f\"Timestamp: {parts[0]}, User: {parts[1]}, IP: {parts[2]}\")\n"
      ],
      "metadata": {
        "id": "Gy9Vd1uQ9e0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь давайте перейдем к более сложным структурам данных — JSON, научимся обогащать наши логи и справляться с \"грязными\" данными, которые неизбежно встречаются в реальной работе."
      ],
      "metadata": {
        "id": "DKQbGtsN9fz0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmlqWpXhU2zP"
      },
      "source": [
        "## Ваши вопросы"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Работа со структурированными данными\n",
        "\n",
        "В файлах могут содержаться структурированные данные:\n",
        "- CSV — таблицы,\n",
        "- JSON — объекты, похожие на словари Python.\n",
        "\n",
        "Наша задача — научиться извлекать из них нужную информацию.\n"
      ],
      "metadata": {
        "id": "k9J4WM0M-4tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Работа с JSON\n",
        "\n",
        "Файл `user_data.json` содержит информацию о пользователях. Этот формат (JSON Lines, где каждая строка — отдельный JSON-объект) очень популярен для логов. Для работы с ним в Python есть встроенный модуль `json`."
      ],
      "metadata": {
        "id": "bt7AXw_W3Zg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "user_data_path = Path('user_data.json')\n",
        "\n",
        "# Посмотрим на первые несколько строк, чтобы понять структуру\n",
        "with open(user_data_path, 'r', encoding='utf-8') as f:\n",
        "    for _ in range(3):\n",
        "        print(f.readline().strip())"
      ],
      "metadata": {
        "id": "ACCb2Zh1-4_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы превратить строку JSON в объект Python, в данном случае в словарь, используется метод `json.loads()` (load string)."
      ],
      "metadata": {
        "id": "PkrMFX_t-7wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример на одной строке\n",
        "json_string = '{\"user_id\": \"user_001\", \"name\": \"Ivan Ivanov\", \"department\": \"Sales\"}'\n",
        "\n",
        "# Превращаем строку в словарь\n",
        "user_dict = json.loads(json_string)\n",
        "\n",
        "print(user_dict)\n",
        "print(f\"Тип данных: {type(user_dict)}\")\n",
        "print(f\"Департамент пользователя: {user_dict['department']}\")"
      ],
      "metadata": {
        "id": "IYGj6COt-8u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Стратегия работы с памятью\n",
        "\n",
        "Это одна из самых важных концепций. Есть два файла:\n",
        "*   `user_data.json` — **маленький**, который можно и нужно целиком загрузить в оперативную память для быстрого доступа;\n",
        "*   `log.csv` — **большой**, который нужно обрабатывать построчно, не загружая целиком.\n",
        "\n",
        "**План действий:**\n",
        "1.  Прочитайте `user_data.json` и сложите все данные в словарь, где ключом будет `user_id`. Это позволит мгновенно получать информацию о пользователе по его ID.\n",
        "2.  Откройте `log.csv` и прочитайте его строка за строкой.\n",
        "3.  Для каждой строки из лога извлеките `user_id` и используйте его для поиска в словаре.\n",
        "\n",
        "Реализуем этап 1: создадим словарь пользователей."
      ],
      "metadata": {
        "id": "axU90z-HA11Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_data_path = Path('user_data.json')\n",
        "users_info = {} # Создаем пустой словарь\n",
        "\n",
        "with open(user_data_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        user = json.loads(line.strip())\n",
        "        # Ключ — user_id, значение — весь словарь с информацией о пользователе\n",
        "        users_info[user['user_id']] = user\n",
        "\n",
        "users_info"
      ],
      "metadata": {
        "id": "YCGqqlCwA3B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получим информацию по user_002\n",
        "print(f\"Данные по user_002: {users_info['user_002']}\")"
      ],
      "metadata": {
        "id": "tmwGTy6e4di6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обогащение данных (map-side join)\n",
        "\n",
        "Расмотрим объединение данных: будем читать большой CSV-лог и для каждой строки забирать нужную информацию из словаря `users_info`.\n",
        "\n",
        "Используем метод словаря `.get()`. Он безопаснее, чем прямой доступ `users_info['user_id']`, потому что позволяет указать значение по умолчанию, если ключ не найден. В `user_data.json` намеренно нет информации о `user_005` — проверим, как `.get()` с этим справится."
      ],
      "metadata": {
        "id": "-Cgu4qJJA5uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vpn_log_path = Path('log.csv')\n",
        "\n",
        "print(\"Timestamp | User ID | Department | Source IP\")\n",
        "\n",
        "with open(log_path, 'r', encoding='utf-8') as f:\n",
        "    next(f) # Пропускаем заголовок\n",
        "    for line in f:\n",
        "        timestamp, user_id, source_ip = line.strip().split(',')\n",
        "\n",
        "        # Безопасно получаем информацию о пользователе из словаря\n",
        "        # Если user_id не найден, user_info будет None\n",
        "        user_info = users_info.get(user_id)\n",
        "\n",
        "        if user_info:\n",
        "            # Если пользователь найден, берём его департамент\n",
        "            department = user_info['department']\n",
        "        else:\n",
        "            # Если нет — ставим заглушку\n",
        "            department = 'Unknown'\n",
        "\n",
        "        print(f\"{timestamp.split('T')[1]} | {user_id} | {department:11} | {source_ip}\")\n"
      ],
      "metadata": {
        "id": "2WbmL-viA7Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Результат:** успешное обогащение логов.\n",
        "\n",
        "Обратите внимание: для `user_005` был корректно подставлен департамент `Unknown`, и скрипт не упал с ошибкой `KeyError`.\n",
        "\n",
        "### Надёжный парсинг CSV\n",
        "\n",
        "Метод `.split(',')` отлично работает, пока в данных не встретится запятая. Это  распространённая проблема, например, в полях с названиями или описаниями.\n",
        "\n",
        "Рассмотрим файл `log_complex.csv`, где поле `user_agent` содержит запятые."
      ],
      "metadata": {
        "id": "9xOKFBdkA9lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complex_csv_path = Path('log_complex.csv')\n",
        "\n",
        "print(\"--- Попытка парсинга сложного CSV через .split() ---\")\n",
        "with open(complex_csv_path, 'r', encoding='utf-8') as f:\n",
        "    next(f)\n",
        "    for line in f:\n",
        "        parts = line.strip().split(',')\n",
        "        print(f\"Найдено частей: {len(parts)}. Данные: {parts}\")"
      ],
      "metadata": {
        "id": "6oju0YzxA-we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Результат:** строка разделилась на слишком много частей.\n",
        "\n",
        "**Решение:** использовать встроенный модуль `csv`, который корректно обрабатывает поля, заключенные в кавычки."
      ],
      "metadata": {
        "id": "7OXAPd7jBAQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open(complex_csv_path, 'r', encoding='utf-8') as f:\n",
        "    # Создаём reader-объект, который будет правильно разбирать строки\n",
        "    reader = csv.reader(f)\n",
        "\n",
        "    # Пропускаем заголовок\n",
        "    header = next(reader)\n",
        "    print(f\"Заголовки: {header}\")\n",
        "\n",
        "    for row in reader:\n",
        "        # Теперь row — это всегда корректный список полей\n",
        "        print(f\"Найдено частей: {len(row)}. Данные: {row}\")\n",
        "        print(f\"User-Agent: {row[3]}\\n\")"
      ],
      "metadata": {
        "id": "kYpNKSMwBBdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** для любых CSV-файлов, кроме самых тривиальных, использование модуля `csv` является профессиональным стандартом, который защищает от ошибок парсинга.\n",
        "\n",
        "### Промежуточные результаты: запись обогащённого лога\n",
        "\n",
        "Соберём всё вместе:\n",
        "- прочитаем `log.csv`,\n",
        "- обогатим его данными из `users_info`\n",
        "- запишем результат в новый файл `enriched_log.csv`, используя модуль `csv` для корректной записи."
      ],
      "metadata": {
        "id": "CmCTxkz9BDEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_log_path = Path('enriched_log.csv')\n",
        "\n",
        "# Открываем исходный лог для чтения и новый лог для записи\n",
        "with open(log_path, 'r', encoding='utf-8') as f_in, \\\n",
        "     open(enriched_log_path, 'w', encoding='utf-8', newline='') as f_out:\n",
        "\n",
        "    # Создаем объекты для чтения и записи\n",
        "    reader = csv.reader(f_in)\n",
        "    writer = csv.writer(f_out)\n",
        "\n",
        "    # Работаем с заголовком\n",
        "    header = next(reader)\n",
        "    new_header = header + ['department', 'name'] # Добавляем новые колонки\n",
        "    writer.writerow(new_header) # Записываем новый заголовок\n",
        "\n",
        "    # Обрабатываем и записываем остальные строки\n",
        "    for row in reader:\n",
        "        user_id = row[1]\n",
        "        user_info = users_info.get(user_id)\n",
        "\n",
        "        if user_info:\n",
        "            department = user_info['department']\n",
        "            name = user_info['name']\n",
        "        else:\n",
        "            department = 'Unknown'\n",
        "            name = 'N/A'\n",
        "\n",
        "        # Добавляем новые данные к старой строке и записываем\n",
        "        new_row = row + [department, name]\n",
        "        writer.writerow(new_row)\n",
        "\n",
        "print(f\"Обогащенный лог успешно сохранен в файл: {enriched_log_path}\")\n",
        "\n",
        "# Посмотрим на результат\n",
        "with open(enriched_log_path, 'r', encoding='utf-8') as f:\n",
        "    for _ in range(5):\n",
        "        print(f.readline().strip())"
      ],
      "metadata": {
        "id": "knt3c8u1BE2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5B2SVYjPSkB"
      },
      "source": [
        "## Ваши вопросы"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Проблемы на практике\n",
        "\n",
        "**Ключевая идея:** скрипт должен работать не только на идеальных, но и на реальных данных; устойчивость к ошибкам — признак профессионального кода.\n",
        "\n"
      ],
      "metadata": {
        "id": "VbCutCJUBbV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кодировки\n",
        "\n",
        "Несоответствие кодировок — одна из самых распространённых проблем, например при открытии файла, который выглядит как обычный текст, вылетает ошибка `UnicodeDecodeError`.\n",
        "\n",
        "**Пример**\n",
        "\n",
        "Есть лог `legacy_log.csv` из устаревшей версии ОС Windows. По умолчанию, ожидаем современную кодировку `UTF-8` и попробуем прочитать лог."
      ],
      "metadata": {
        "id": "iUi-qyTB8hgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "broken_log_path = Path('legacy_log.csv')\n",
        "\n",
        "\n",
        "with open(broken_log_path, 'r', encoding='utf-8') as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "id": "cnzB20tpBcd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Результат:** ошибка.\n",
        "\n",
        "**Причина:** файл был сохранён в устаревшей 8-битной кодировке `cp1251`, популярной в русскоязычных версиях Windows, где каждый кириллический символ кодируется одним байтом, а `UTF-8` — это многобайтная кодировка. В таком случае парсер видит не валидную для `UTF-8` последовательность байт и аварийно останавливается.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Решение** для случая, когда кодировка известна или её можно угадать: указать кодировку в `open()`."
      ],
      "metadata": {
        "id": "MLVdTz-5Bd94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(broken_log_path, 'r', encoding='cp1251') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "27q7ePj2Be5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Результат:** всё работает.\n",
        "\n",
        "**Вывод:** при ошибке `UnicodeDecodeError`сперва нужно попробовать указать другую кодировку в `open()`. Наиболее распространённые после `utf-8` кодировки: `cp1251` (для файлов из устаревших версий ОС Windows) и `latin-1`.  \n",
        "\n"
      ],
      "metadata": {
        "id": "GPgJeEMWBgBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Решение** для случая, когда кодировка не известна: автоматическое определение кодировки с `chardet`.\n",
        "\n",
        "Библиотека `chardet` анализирует байтовое содержимое файла и с высокой долей вероятности определяет его кодировку.\n"
      ],
      "metadata": {
        "id": "RgMiX3yKKxVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем функцию, которая сначала определяет кодировку, а потом использует её для чтения файла."
      ],
      "metadata": {
        "id": "U4qEGFFQNBed"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Mx0vimNaIBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet\n",
        "\n",
        "def read_file_with_autodetect(filepath):\n",
        "    \"\"\"\n",
        "    Читает файл, автоматически определяет его кодировку.\n",
        "    \"\"\"\n",
        "    # Сначала читаем файл в бинарном режиме ('rb')\n",
        "    with open(filepath, 'rb') as f:\n",
        "        raw_data = f.read()\n",
        "\n",
        "    # Анализируем байты с помощью chardet\n",
        "    detection = chardet.detect(raw_data)\n",
        "    encoding = detection['encoding']\n",
        "    confidence = detection['confidence']\n",
        "\n",
        "    print(f\"Обнаружена кодировка: {encoding} с уверенностью {confidence:.0%}\")\n",
        "\n",
        "    # Декодируем байты в строку, используя определённую кодировку\n",
        "    text = raw_data.decode(encoding)\n",
        "    return text\n",
        "\n",
        "# Используем умную функцию\n",
        "print(\"\\n--- Автоматическое определение и чтение legacy_log.csv ---\")\n",
        "content = read_file_with_autodetect(broken_log_path)\n",
        "print(content)"
      ],
      "metadata": {
        "id": "sZtwLsuzNCxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Бинарные данные и `pickle`\n",
        "\n",
        "Модуль `pickle` сериализует объект Python напрямую в поток байтов  и таким образом даёт возможность сохранить целиком сложный объект Python: словарь, список, модель машинного обучения.\n",
        "\n",
        "Для работы с байтами используются бинарные режимы:\n",
        "- `'wb'` — write bytes;\n",
        "- `'rb'` — read bytes."
      ],
      "metadata": {
        "id": "EJ9vqPoUKwhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Словарь с данными\n",
        "data_to_save = {'user_id': 'user_001', 'department': 'Sales', 'permissions': [1, 2, 5]}\n",
        "pickle_path = Path('user_data.pickle')\n",
        "\n",
        "# Сохраняем объект в файл в бинарном режиме\n",
        "with open(pickle_path, 'wb') as f:\n",
        "    pickle.dump(data_to_save, f)\n",
        "\n"
      ],
      "metadata": {
        "id": "JY00GLfbBhua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Теперь загрузим его обратно\n",
        "with open(pickle_path, 'rb') as f:\n",
        "    loaded_data = pickle.load(f)\n",
        "\n",
        "print(loaded_data)\n",
        "print(f\"Тип данных: {type(loaded_data)}\")\n",
        "print(f\"Права доступа: {loaded_data['permissions']}\")"
      ],
      "metadata": {
        "id": "B0arkE0s8wUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Важно:** не используйте `pickle.load()` на файлах из недоверенного источника, используйте `pickle` только для собственных данных.\n",
        "\n",
        "Файл `.pickle` может содержать вредоносный код, который выполнится на устройстве в момент загрузки. Это одна из самых серьёзных уязвимостей (remote code execution, RCE)."
      ],
      "metadata": {
        "id": "rCIN7caqBi2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Работа с окружением\n",
        "\n",
        "**Ключевые идеи:**\n",
        "- скрипты работают не изолировнно, они должны уметь взаимодействовать с файловой структурой, безопасно управлять своими зависимостями;\n",
        "- скрипты должны быть организованы так, чтобы их легко было поддерживать и расширять.\n",
        "\n"
      ],
      "metadata": {
        "id": "yKbUdjPUBkCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сканирование с `os.walk()`\n",
        "\n",
        "**Пример:** необходимо проанализировать все `.log` файлы с эндпойнтов, которые лежат в сложной структуре папок внутри `endpoint_logs/`.\n",
        "\n",
        "Рассмотрим два основных способа рекурсивного обхода дерева каталогов."
      ],
      "metadata": {
        "id": "gTNpq4Co8849"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Классический способ: `os.walk()`**\n",
        "\n",
        "Функция `os.walk()` обходит все папки, начиная с указанной, и на каждом шаге предоставляет кортеж из трёх элементов:\n",
        "- путь к текущей папке,\n",
        "- список вложенных папок,\n",
        "- список файлов в текущей папке."
      ],
      "metadata": {
        "id": "1A1Jq62XAma6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "root_log_dir = Path('endpoint_logs')\n",
        "\n",
        "print(f\"--- Сканирование директории '{root_log_dir}' с помощью os.walk() ---\")\n",
        "log_files_found = []\n",
        "\n",
        "for current_path, subdirectories, files in os.walk(root_log_dir):\n",
        "    print(f\"\\nВхожу в папку: {current_path}\")\n",
        "    print(f\"  Подпапки: {subdirectories}\")\n",
        "    print(f\"  Файлы: {files}\")\n",
        "\n",
        "    for filename in files:\n",
        "        if filename.endswith('.log'):\n",
        "            full_path = Path(current_path) / filename\n",
        "            log_files_found.append(full_path)\n",
        "            print(f\"    -> Найден целевой лог: {full_path}\")\n",
        "\n",
        "print(f\"\\nИтог: Найдено {len(log_files_found)} лог-файлов.\")"
      ],
      "metadata": {
        "id": "P1_ev0T3Bl0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Современный способ: `pathlib.rglob()`**  \n",
        "У библиотеки `pathlib` есть более элегантное и лаконичное решение — метод `.rglob()`, который позволяет искать файлы по шаблону (glob-паттерну) рекурсивно.\n",
        "\n"
      ],
      "metadata": {
        "id": "z8wwMw02BoQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rglob('**/*.log') означает — искать рекурсивно все файлы, заканчивающиеся на .log; символ ** означает — в любой вложенной директории.\n",
        "log_files_found_pathlib = list(root_log_dir.rglob('**/*.log'))\n",
        "\n",
        "for path in log_files_found_pathlib:\n",
        "    print(f\"Найден файл: {path}\")\n",
        "\n",
        "print(f\"\\nИтог: Найдено {len(log_files_found_pathlib)} лог-файлов.\")"
      ],
      "metadata": {
        "id": "LSzoORHLAyNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Результат:** `pathlib.rglob()` позволяет решить эту задачу в одну строку, что это предпочтительный метод для большинства задач поиска файлов.\n"
      ],
      "metadata": {
        "id": "4sjMjM7NA1M6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Изоляция и безопасность: `venv`\n",
        "\n",
        "Внешние библиотеки устанавливаются командой `pip install ...`, по умолчанию, — в глобальное хранилище Python на устройстве.\n",
        "\n",
        "**Проблемы установки внешних библиотек в глобальное хранилище**\n",
        "*   **Конфликт версий:** если один скрипт  требует `requests==2.25.0`, а другой проект, например для пентеста, требует `requests==2.28.0`, глобальная установка приведёт к тому, что один из проектов перестанет работать.\n",
        "*   **Безопасность (атака dependency confusion):** если вы работаете в корпоративной сети, злоумышленник может создать в ней вредоносный пакет с именем, как у публичной библиотеки, когда скрипт не изолирован, он может случайно установить и запустить этот вредоносный код.\n",
        "*   **Воспроизводимость:** тяжело переносить такой скрипт со всеми нужными библиотеками и их версиями на другой сервер.\n",
        "\n",
        "**Решение:** виртуальные окружения (`venv`).\n",
        "\n",
        "`venv` — стандартный модуль Python, который создаёт для проекта изолированную песочницу с собственным Python-интерпретатором и папкой для библиотек.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Как это работает\n",
        "\n",
        "Важно: представлены команды для терминала, а не для Jupyter Notebook:"
      ],
      "metadata": {
        "id": "Q_K91FyeAuIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Создайте папку для проекта\n",
        "mkdir incident-analysis-tool\n",
        "cd incident-analysis-tool\n",
        "\n",
        "# 2. Создайте внутри этой папки виртуальное окружение.\n",
        "# Назовите его 'venv' — это общепринятое соглашение.\n",
        "python -m venv venv\n",
        "\n",
        "# 3. Активируйте окружение.\n",
        "# На Windows:\n",
        "# .\\venv\\Scripts\\activate\n",
        "# На macOS/Linux:\n",
        "# source venv/bin/activate\n",
        "# После активации командная строка изменится, показывая (venv).\n",
        "\n",
        "# 4. Установите зависимости. Они попадут только в эту песочницу.\n",
        "pip install chardet pandas\n",
        "\n",
        "# 5. Зафиксируйте зависимости в файле requirements.txt\n",
        "pip freeze > requirements.txt\n",
        "\n",
        "# Результат — в будущем возможно легко воссоздать окружение:\n",
        "# pip install -r requirements.txt\n",
        "\n",
        "# 6. Деактивируйте окружение, когда закончите работу.\n",
        "deactivate"
      ],
      "metadata": {
        "id": "24im0owbBphQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** всегда начинайте новый проект с создания и активации виртуального окружения.\n"
      ],
      "metadata": {
        "id": "PtgSrKeLBqmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модульность: отделение логики от данных с `config.py`\n",
        "\n",
        "\n",
        "Статические данные (хеши файлов, API-ключи и пр.), необходимые для проекта, принято выносить из кода в отдельный конфигурационный файл `config.py`.\n",
        "\n",
        "Почему держать статические данные в коде — плохая практика:\n",
        "*   затрудняет обновление данных;\n",
        "*   смешивает логику скрипта (что делать) с его конфигурацией (с чем делать);\n",
        "*   небезопасно, например если вы захотите поделиться кодом, забыв удалить оттуда ключи.\n",
        "\n",
        "Создадим простой Python-файл `config.py`."
      ],
      "metadata": {
        "id": "fE6gr_uCBRHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Этот блок создает файл config.py в текущей директории\n",
        "config_content = \"\"\"\n",
        "# База знаний для анализа инцидентов\n",
        "\n",
        "# IP-адреса, которые считаются подозрительными при подключении к VPN\n",
        "# Например, публичные DNS или известные адреса TOR exit nodes.\n",
        "SUSPICIOUS_IPS = {\n",
        "    \"8.8.8.8\",       # Google DNS\n",
        "    \"1.1.1.1\",       # Cloudflare DNS\n",
        "    \"193.232.147.4\"  # IP из известного списка угроз\n",
        "}\n",
        "\n",
        "# Департаменты, требующие особого внимания при анализе\n",
        "HIGH_RISK_DEPARTMENTS = {\n",
        "    \"Development\",\n",
        "    \"Executive\"\n",
        "}\n",
        "\"\"\"\n",
        "with open('config.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "print(\"Файл config.py успешно создан.\")"
      ],
      "metadata": {
        "id": "Ei2rdirjBr4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь можно импортировать этот файл в основной скрипт как обычный модуль и использовать определённые в нём переменные.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "502YTXu1Bt5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем собственный модуль конфигурации\n",
        "import config\n",
        "\n",
        "print(\"--- Загруженные индикаторы компрометации (IoC) ---\")\n",
        "print(\"Подозрительные IP:\", config.SUSPICIOUS_IPS)\n",
        "\n",
        "# Теперь можно использовать эту конфигурацию в логике скрипта\n",
        "test_ip = \"8.8.8.8\"\n",
        "if test_ip in config.SUSPICIOUS_IPS:\n",
        "    print(f\"\\nПроверка: IP-адрес {test_ip} находится в списке подозрительных!\")\n",
        "else:\n",
        "    print(f\"\\nПроверка: IP-адрес {test_ip} не является подозрительным.\")"
      ],
      "metadata": {
        "id": "UH2bXu5NB-e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Формирование отчёта\n",
        "\n",
        "\n",
        "**Ключевая идея:** результат работы аналитика — не просто найденные артефакты, а понятный, структурированный отчёт, на основе которого возможно принимать решения. Скрипт должен не только найти подозрительные события, но и представить их в человекочитаемом виде.\n",
        "\n",
        "**Финальные задачи:**\n",
        "\n",
        "1. Прочитать основной лог `vpn_log.csv`.\n",
        "2. Обогатить каждую запись данными о пользователе из `user_data.json`.\n",
        "3. Используя базу знаний из `config.py`, выявить все сессии, которые были установлены с подозрительных IP-адресов, используя базу знаний из `config.py`.\n",
        "4. Записать результат в финальный отчёт `incident_report.txt`.\n",
        "\n",
        "<br>\n",
        "\n",
        "Напишем скрипт, который объединит все концепции, которые мы изучили:\n",
        "*   `pathlib` для элегантной работы с путями;\n",
        "*   чтение справочника JSON в память для быстрого доступа;\n",
        "*   построчную обработку большого CSV-файла с помощью модуля `csv`;\n",
        "*   `try-except` для устойчивости;\n",
        "*   импорт и использование собственного модуля `config`;\n",
        "*   безопасную запись в файл отчёта с использованием `with open`."
      ],
      "metadata": {
        "id": "e14M87__B86e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "\n",
        "# Может потребоваться перезагрузка, если вы меняли config.py во время работы\n",
        "import importlib\n",
        "import config\n",
        "importlib.reload(config)\n",
        "\n",
        "\n",
        "# --- Шаг 1. Подготовка путей к файлам ---\n",
        "vpn_log_path = Path('log.csv')\n",
        "user_data_path = Path('user_data.json')\n",
        "report_path = Path('incident_report.txt')\n",
        "\n",
        "# --- Шаг 2. Загрузка данных для обогащения (справочника) в память ---\n",
        "print(f\"Загружаю данные пользователей из {user_data_path}...\")\n",
        "users_info = {}\n",
        "try:\n",
        "    with open(user_data_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            user = json.loads(line.strip())\n",
        "            users_info[user['user_id']] = user\n",
        "    print(f\"Успешно загружено {len(users_info)} пользователей.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Критическая ошибка: Файл {user_data_path} не найден!\")\n",
        "    # В реальном скрипте здесь можно было бы завершить выполнение\n",
        "    # exit()\n",
        "\n",
        "# --- Шаг 3. Построчная обработка основного лога и формирование отчёта ---\n",
        "print(f\"Анализирую основной лог {vpn_log_path}...\")\n",
        "found_incidents = 0\n",
        "\n",
        "# Используем 'w' для создания и очистки файла отчёта\n",
        "with open(report_path, 'w', encoding='utf-8') as f_report:\n",
        "    f_report.write(\"--- Отчет о подозрительных сессиях VPN ---\\n\")\n",
        "    f_report.write(\"=\" * 45 + \"\\n\\n\")\n",
        "\n",
        "\n",
        "    # Открываем основной лог для чтения\n",
        "    with open(vpn_log_path, 'r', encoding='utf-8', newline='') as f_log:\n",
        "        reader = csv.reader(f_log)\n",
        "        next(reader) # Пропускаем заголовок\n",
        "\n",
        "        # --- 5.2. Ключевая логика расследования ---\n",
        "        for row in reader:\n",
        "            timestamp, user_id, source_ip = row\n",
        "\n",
        "            # Проверка: является ли IP-адрес подозрительным\n",
        "            if source_ip in config.SUSPICIOUS_IPS:\n",
        "                found_incidents += 1\n",
        "\n",
        "                # --- 5.3. Обогащение и запись инцидента в отчёт ---\n",
        "\n",
        "                # Получаем данные о пользователе, используя .get() для безопасности\n",
        "                user_data = users_info.get(user_id, {})\n",
        "                name = user_data.get('name', 'N/A')\n",
        "                department = user_data.get('department', 'Unknown')\n",
        "\n",
        "                # Формируем запись для отчёта\n",
        "                report_entry = (\n",
        "                    f\"Инцидент №{found_incidents}:\\n\"\n",
        "                    f\"  -> Время: {timestamp}\\n\"\n",
        "                    f\"  -> Подозрительный IP: {source_ip}\\n\"\n",
        "                    f\"  -> Пользователь: {name} (ID: {user_id})\\n\"\n",
        "                    f\"  -> Департамент: {department}\\n\\n\"\n",
        "                )\n",
        "\n",
        "                # Записываем инцидент в файл. Режим 'a' здесь не нужен,\n",
        "                # так как мы держим файл открытым на протяжении всего цикла.\n",
        "                f_report.write(report_entry)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"\\nАнализ завершен. Найдено инцидентов: {found_incidents}\")\n",
        "print(f\"Отчёт сохранен в файл: {report_path}\")\n",
        "\n",
        "# --- Шаг 4. Вывод содержимого отчёта для проверки ---\n",
        "print(\"\\n--- СОДЕРЖИМОЕ ОТЧЕТА ---\")\n",
        "with open(report_path, 'r', encoding='utf-8') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "eO7RcmQWBvsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Результат:** скрипт успешно отработал.\n",
        "\n",
        "Скрипт проанализировал основной лог, сравнил IP-адреса с базой знаний, обогатил найденные события данными о пользователях и сформировал чёткий, человекочитаемый отчёт, который можно немедленно передать старшему аналитику.\n"
      ],
      "metadata": {
        "id": "kaaOqBJoChrx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R4KSU4cyBa1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxXc7JCJDw-D"
      },
      "source": [
        "## Ваши вопросы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EooS2zvp7_4"
      },
      "source": [
        "# Итоги"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Научились работать с файлами и пакетами в Python на практических примерах."
      ],
      "metadata": {
        "id": "9uBgmdD10bUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📱 Делюсь полезными материалами о Python:\n",
        "- [Telegram](https://t.me/pythontalk)"
      ],
      "metadata": {
        "id": "3KIcaiMK7jCK"
      }
    }
  ]
}